{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwanda2426/unsupervised-predict-streamlit-template/blob/master/Team_14%20notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBg6Fpz9Temh"
      },
      "source": [
        "<img src=\"https://explore-datascience.net/images/images_admissions2/main-logo.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSKxLO7VTemm"
      },
      "source": [
        "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/sql_tmdb.jpg?raw=true\" width=90%/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mve0fr3rTemn"
      },
      "source": [
        "# Streamlit-based Movie Recommender System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InnMg-PxTemn"
      },
      "source": [
        "## Team 14 : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LIQt3dWTemo"
      },
      "source": [
        "## Table of contents\n",
        "1. [Introduction](#intro)\n",
        "2. [Data Collection](#data)\n",
        "3. [Data Preprocessing](#cleaning)\n",
        "4. [Exploratory Data Analysis](#EDA)\n",
        "5. [Feature Engineering And Selection](#features)\n",
        "6. [Model Building And Evaluation](#model)\n",
        "7. [Model Hyperparameter Tuning](#tuning)\n",
        "8. [Conclusion](#conclusion)\n",
        "9. [References](#references)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgZPzuvXTemo"
      },
      "source": [
        "<a id=\"intro\"></a>\n",
        "# 1. **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRsXFTyiTqM1"
      },
      "source": [
        "In our daily life when we are shopping online, or looking for a movie to watch, we normally ask our friends or search for it. And when they recommend something that we do not like yet they enjoyed it. what a waste of time right. So what about if there is a system that can understand you, and recommend for you based on your interests, that would be so cool.\n",
        "\n",
        "The growth of the internet has resulted in an enormous amount of online data and information available to us. Tools like a recommender system allow us to filter the information which we want or need. Recommender systems can be utilized in many contexts, one of which is a playlist generator for video, movie or music services. \n",
        "Recommendation systems are becoming increasingly important in today’s extremely busy world. People are always short on time with the myriad tasks they need to accomplish in the limited 24 hours. Therefore, the recommendation systems are important as they help them make the right choices, without having to expend their cognitive resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dhnq3aCTqM-"
      },
      "source": [
        "### **Problem Statement**\n",
        "In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals are exposed to the content that is relevant to them in one way or another. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options. If customers are not exposed to a content relevant to them, may decide to look for alternatives which may provide better content.\n",
        "\n",
        "### **Objectives**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMZEVYLXTqNB"
      },
      "source": [
        "The key objective is to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OVt8WFpTqNF"
      },
      "source": [
        "### **Literature Review**\n",
        "\n",
        "**What are recommender systems?**\n",
        "\n",
        "Simply put, recommender systems are the systems that are designed to recommend things to the user based on many different factors. These systems predict the most likely product that the users are most likely to purchase and are of interest to. Companies like Netflix, Amazon, etc. use recommender systems to help their users to identify the correct product or movies for them. \n",
        "\n",
        "The purpose of a recommendation system basically is to search for content that would be interesting to an individual. Moreover, it involves a number of factors to create personalised lists of useful and interesting content specific to each user. Recommendation systems are Artificial Intelligence based algorithms that skim through all possible options and create a customized list of items that are interesting and relevant to an individual. These results are based on their profile, search/browsing history, what other people with similar traits/demographics are watching, and how likely are you to watch those movies. This is achieved through predictive modeling and heuristics with the data available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhb1-skpTqNL"
      },
      "source": [
        "#### **Content-Based Filtering**\n",
        "\n",
        "Content-based filtering is a type of recommender system that attempts to guess what a user may like based on that user's activity. Content-based filtering makes recommendations by using keywords and attributes assigned to objects in a database (e.g., items in an online marketplace) and matching them to a user profile.\n",
        "\n",
        "**Why use content-based filtering?**\n",
        "- No data from other users is required to start making recommendations.\n",
        "- Recommendations are highly relevant to the user.\n",
        "- You avoid the “cold start” problem.\n",
        "- Recommendations are transparent to the user. Highly relevant recommendations send a message of openness to the user, bolstering their trust level in offered recommendations.\n",
        "\n",
        "\n",
        "**Challenges of content-based filtering**\n",
        "- There’s a lack of novelty and diversity.\n",
        "- Scalability is a challenge. Every time a new product or service or new content is added, its attributes must be defined and tagged.\n",
        "- Attributes may be incorrect or inconsistent. Content-based recommendations are only as good as the subject-matter experts tagging items.\n",
        "\n",
        "\n",
        "#### **Collaborative Filtering**\n",
        "The idea behind collaborative filtering is to consider users’ opinions on different videos and recommend the best video to each user based on the user’s previous rankings and the opinion of other similar types of users.\n",
        "\n",
        "**Why use collaborative filtering?**\n",
        "- It does not need a movie’s side knowledge like genres.\n",
        "- It uses information collected from other users to recommend new items to the current user.\n",
        "- Even when no information on an item is available, we still can predict the item rating without waiting for a user to purchase it.\n",
        "- Captures the change in user interests over time: Focusing solely on content does not provide any flexibility on the user's perspective and their preferences.\n",
        "\n",
        "\n",
        "**Challenges of collaborative filtering**\n",
        "- Cannot handle well fresh items with no ratings.\n",
        "- Hard to include side features for query/item.\n",
        "- Cannot handle well fresh users with no relations to other users.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBFTRXNPTemp"
      },
      "source": [
        "<a id=\"data\"></a>\n",
        "# 2. **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq5-1ZQDTemp"
      },
      "source": [
        "## **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoAMG4MbTemq"
      },
      "outputs": [],
      "source": [
        "!pip install comet_ml\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-01-12T15:45:14.612784Z",
          "iopub.status.busy": "2022-01-12T15:45:14.611982Z",
          "iopub.status.idle": "2022-01-12T15:45:14.617015Z",
          "shell.execute_reply": "2022-01-12T15:45:14.616196Z",
          "shell.execute_reply.started": "2022-01-12T15:45:14.612744Z"
        },
        "id": "QQGZ7vbrTemr",
        "outputId": "c84fa366-03f6-4976-af4a-d11a9d2b4e8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/kwanda2426/streamlit-based-movie-recommender-system/d69f8ff97ef5447fa556f633a134fb40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "\n",
        "# Create an experiment with your api key\n",
        "experiment = Experiment(\n",
        "    api_key=\"cDBGt9YOCyyinNTUvxRUB3hxd\",\n",
        "    project_name=\"streamlit-based-movie-recommender-system\",\n",
        "    workspace=\"kwanda2426\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaaHNd5ZTemt"
      },
      "source": [
        "We use comet to run different experiments while saving the ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-12T15:45:14.618797Z",
          "iopub.status.busy": "2022-01-12T15:45:14.618331Z",
          "iopub.status.idle": "2022-01-12T15:45:14.638883Z",
          "shell.execute_reply": "2022-01-12T15:45:14.637944Z",
          "shell.execute_reply.started": "2022-01-12T15:45:14.618750Z"
        },
        "id": "QxiTHtj8Temu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "5f4f4a8c-502e-4cb5-e977-1cb6de3969d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-318ff5c2901c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# datetime\n",
        "import datetime\n",
        "\n",
        "# Libraries for data preparation and model building\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise import SVD\n",
        "import recmetrics\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from surprise.accuracy import rmse\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# saving model\n",
        "import pickle\n",
        "\n",
        "#ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "#making sure that we can see all rows and cols\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUiICh_RTemu"
      },
      "source": [
        "### **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83EpWSbSUfjF",
        "outputId": "eddf0ff6-2812-45ec-9401-848d4948f96d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrGAhBGnTemv"
      },
      "source": [
        "The basic process of loading data from a CSV file into a Pandas DataFrame (with all going well) is achieved using the “read_csv” function in Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-12T15:45:14.641227Z",
          "iopub.status.busy": "2022-01-12T15:45:14.640362Z",
          "iopub.status.idle": "2022-01-12T15:45:15.532785Z",
          "shell.execute_reply": "2022-01-12T15:45:15.531734Z",
          "shell.execute_reply.started": "2022-01-12T15:45:14.641153Z"
        },
        "id": "JFibvO4ITemv"
      },
      "outputs": [],
      "source": [
        "# imdb\n",
        "imdb_df = pd.read_csv('C:/Users/Tshegofatso/Downloads/edsa-movie-recommendation-wilderness/imdb_data.csv')\n",
        "\n",
        "# movies\n",
        "movies_df = pd.read_csv('C:/Users/Tshegofatso/Downloads/edsa-movie-recommendation-wilderness/movies.csv')\n",
        "\n",
        "# movies\n",
        "tags_df = pd.read_csv('C:/Users/Tshegofatso/Downloads/edsa-movie-recommendation-wilderness/tags.csv')\n",
        "\n",
        "# train \n",
        "train = pd.read_csv('C:/Users/Tshegofatso/Downloads/edsa-movie-recommendation-wilderness/train.csv')\n",
        "\n",
        "# test\n",
        "test = pd.read_csv('C:/Users/Tshegofatso/Downloads/edsa-movie-recommendation-wilderness/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17MlA9nyTqNu"
      },
      "source": [
        "<a id=\"cleaning\"></a>\n",
        "## 3. **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDAsgOkqTqNv"
      },
      "source": [
        "Data preprocessing is a technique that involves taking in raw data and transforming it into a understandable format and useful. The technique includes data cleaning, intergration, transformation, reduction and discretization. The data preprocessing plan will include the following processes:\n",
        "\n",
        "- **Data cleaning**\n",
        "\n",
        "- **Table merging process**\n",
        "\n",
        "- **Dealing with missing values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHa7pZwPTqNx"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kE4szh2TqNy"
      },
      "source": [
        "Data cleaning is important because it improves your data quality and in doing so, increases overall productivity. When you clean your data, all outdated or incorrect information is gone – leaving you with the highest quality information. We aim to determine inaccurate, incomplete, or unreasonable data and then improve quality by correcting detected errors and omissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T9jnnNBTqNz"
      },
      "outputs": [],
      "source": [
        "# create copies of the dataframes\n",
        "\n",
        "imdb_df = imdb_df.copy()\n",
        "movies_df = movies_df.copy()\n",
        "train_df = train.copy()\n",
        "test_df = test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQQiTI33TqN0"
      },
      "outputs": [],
      "source": [
        "# merging dataframe\n",
        "\n",
        "train_df = pd.merge(movies_df, imdb_df, on = 'movieId')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DiBUABgTqN1"
      },
      "source": [
        "### Checking for missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0CsnVFBTqN2"
      },
      "source": [
        "The problem of missing value is quite common in many real-life datasets. Missing value can bias the results of the machine learning models and/or reduce the predictive accuracy of the model, hence it is crucial to know how much is missing and what to do with that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jGS0HEVTqN3",
        "outputId": "afd095ac-1d7d-4b0a-a7b1-1932fe51932a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "movieId           0.000000\n",
              "title             0.000000\n",
              "genres            0.000000\n",
              "title_cast       38.868334\n",
              "director         38.281187\n",
              "runtime          45.624548\n",
              "budget           70.711011\n",
              "plot_keywords    42.153945\n",
              "dtype: float64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Percentage of missing values\n",
        "(train_df.isnull().sum()/len(train_df))*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz24gvAQTqN4"
      },
      "source": [
        "We can see that **title_cast** is missing about **36.9%**, the **director** column is missing **36.2%**, **runtime** is missing **44.3%**, **budget** is missing **71.0%**, **plot_keywords** is missing **40.6%**.\n",
        "The **budget** column since we missing a lot of data we will **drop** the column since **we can't make reliable analysis on it** and the others we can't impute reliable like the cast. The function that removes noise deals with the missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LJeqYmXTqN5"
      },
      "source": [
        "#### Removing noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuFb0gpCTqN7"
      },
      "source": [
        "Data that can not be processed/interpreted by a machine is classified as noisy data. Text data contain a lot of noise, this comes in a form of special characters such as hashtags, punctuation and numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyU1X_aHTqN8"
      },
      "source": [
        "- We start by changing the datatype of text data to string for better handling and manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNmCvJ_STqN-"
      },
      "outputs": [],
      "source": [
        "# change data types\n",
        "train_df['genres'] = train_df.genres.astype(str)\n",
        "train_df['title_cast'] = train_df.title_cast.astype(str)\n",
        "train_df['director'] = train_df.director.astype(str)\n",
        "train_df['plot_keywords'] = train_df.plot_keywords.astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEbFY51ETqOA"
      },
      "source": [
        "- Change the text to lower case.\n",
        "\n",
        "- Replace the vertical bar with a comma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9zswqCPTqOB"
      },
      "outputs": [],
      "source": [
        "# Every genre is separated by a | \n",
        "train_df['genres'] = train_df['genres'].map(lambda x: x.lower().split('|'))\n",
        "\n",
        "# Every title cast is separated by a | so we simply have to call the split function on | and separate them by ,\n",
        "train_df['title_cast'] = train_df['title_cast'].str.split('|')\n",
        "\n",
        "# And we will do the same thing for the plot keywords\n",
        "train_df['plot_keywords'] = train_df['plot_keywords'].str.split('|')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZk8XMQATqOD"
      },
      "source": [
        "Combine the name and surname in the title_cast and director columns, hence creating one word for the uniqueness of a person's name. If no name exists, the function will leave a space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HetwnMT6TqOE"
      },
      "outputs": [],
      "source": [
        "def string_function(x):\n",
        "    \"\"\"combines name and surname into one name\n",
        "    and return results as one name.\n",
        "    \n",
        "    if no name exists returns a space\"\"\"\n",
        "    if isinstance(x, list):\n",
        "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
        "    else:\n",
        "        #Check if director exists. If not, return empty string\n",
        "        if isinstance(x, str):\n",
        "            return str.lower(x.replace(\" \", \"\"))\n",
        "        else:\n",
        "            return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzH6EH96TqOG"
      },
      "outputs": [],
      "source": [
        "cols = ['title_cast','director']\n",
        "\n",
        "for col in cols:\n",
        "    train_df[col] = train_df[col].apply(string_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGWq3wYaTqOI"
      },
      "source": [
        "The resulting data has every text column in lower case, separated by a comma. The name and surname combined for title_cast and director columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOYYD08eTemv"
      },
      "source": [
        "<a id=\"EDA\"></a>\n",
        "## 4. **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt3nwtD9Temw"
      },
      "source": [
        "#### Data overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdB3NajVTemw"
      },
      "source": [
        "This gives an overview of the dataset that is more interesting than the others, i.e imdb, movies, train and test datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhF0WTNhTemw"
      },
      "source": [
        "#### IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Iuojnz3VTemw",
        "outputId": "c0061208-92e0-46ca-b4bd-dc3667e6258e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a3fdfe59a4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking how our imdb dataset looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rows    : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imdb_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Checking how our imdb dataset looks like\n",
        "print(\"Rows    : \", imdb_df.shape[0])\n",
        "\n",
        "print(\"Columns : \", imdb_df.shape[1])\n",
        "\n",
        "print(\"\\nMissing values: \", imdb_df.isnull().sum().values.sum())\n",
        "\n",
        "print(\"\\nInformation about the data: \")\n",
        "print(\"  \\n\", imdb_df.info())\n",
        " \n",
        "print(\"\\nAbout the data: \\n\")\n",
        "\n",
        "# Check how many unique items are in each column of the dateframe\n",
        "for col_name in imdb_df.columns:\n",
        "    unique_out = len(imdb_df[col_name].unique())\n",
        "    print(f\"Feature '{col_name}' has {unique_out} unique categories\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CeA6bhDTemx"
      },
      "source": [
        "**Movies dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aCKUEHD3Temx",
        "outputId": "934f62e0-8640-45c3-c78b-108691dc28a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0cd4c7cb4438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking how our movies dataset looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rows    : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovies_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'movies_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Checking how our movies dataset looks like\n",
        "print(\"Rows    : \", movies_df.shape[0])\n",
        "\n",
        "print(\"Columns : \", movies_df.shape[1])\n",
        "\n",
        "print(\"\\nMissing values: \", movies_df.isnull().sum())\n",
        "\n",
        "print(\"\\nInformation about the data: \")\n",
        "print(\"  \\n\", movies_df.info())\n",
        " \n",
        "print(\"\\nAbout the data: \\n\")\n",
        "\n",
        "# Check how many unique items are in each column of the dateframe\n",
        "for col_name in movies_df.columns:\n",
        "    unique_out = len(movies_df[col_name].unique())\n",
        "    print(f\"Feature '{col_name}' has {unique_out} unique categories\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeIRPnCtTemx"
      },
      "source": [
        "**Tags dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0L679zh4Temx",
        "outputId": "34ccaa9f-e353-4e8c-f181-93a62714619d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5f501eb99532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking how our tags dataset looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rows    : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tags_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Checking how our tags dataset looks like\n",
        "print(\"Rows    : \", tags_df.shape[0])\n",
        "\n",
        "print(\"Columns : \", tags_df.shape[1])\n",
        "\n",
        "print(\"\\nMissing values: \", tags_df.isnull().sum())\n",
        "\n",
        "print(\"\\nInformation about the data: \")\n",
        "print(\"  \\n\", tags_df.info())\n",
        " \n",
        "print(\"\\nAbout the data: \\n\")\n",
        "\n",
        "# Check how many unique items are in each column of the dateframe\n",
        "for col_name in tags_df.columns:\n",
        "    unique_out = len(tags_df[col_name].unique())\n",
        "    print(f\"Feature '{col_name}' has {unique_out} unique categories\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl5VWwOyTemy"
      },
      "source": [
        "**Train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4I_wiWXTemy"
      },
      "outputs": [],
      "source": [
        "# Checking how our train dataset looks like\n",
        "print(\"Rows    : \", train_df.shape[0])\n",
        "\n",
        "print(\"Columns : \", train_df.shape[1])\n",
        "\n",
        "print(\"\\nMissing values: \", train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nInformation about the data: \")\n",
        "print(\"  \\n\", train_df.info())\n",
        " \n",
        "print(\"\\nAbout the data: \\n\")\n",
        "\n",
        "# Check how many unique items are in each column of the dateframe\n",
        "for col_name in train_df.columns:\n",
        "    unique_out = len(train_df[col_name].unique())\n",
        "    print(f\"Feature '{col_name}' has {unique_out} unique categories\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gXZU0K5Temy"
      },
      "source": [
        "**Test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYpLnYOdTemy"
      },
      "outputs": [],
      "source": [
        "# Checking how our test dataset looks like\n",
        "print(\"Rows    : \", test_df.shape[0])\n",
        "\n",
        "print(\"Columns : \", test_df.shape[1])\n",
        "\n",
        "print(\"\\nMissing values: \", test_df.isnull().sum().values.sum())\n",
        "\n",
        "print(\"\\nInformation about the data: \")\n",
        "print(\"  \\n\", test_df.info())\n",
        " \n",
        "print(\"\\nAbout the data: \\n\")\n",
        "\n",
        "# Check how many unique items are in each column of the dateframe\n",
        "for col_name in test_df.columns:\n",
        "    unique_out = len(test_df[col_name].unique())\n",
        "    print(f\"Feature '{col_name}' has {unique_out} unique categories\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asEqBSi-Temz"
      },
      "source": [
        "### Splitting the genres and title casts into lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDh50JC7Temz"
      },
      "outputs": [],
      "source": [
        "#extracting released year\n",
        "movies = movies_df.copy()\n",
        "movies['release_year']=movies['title'].str[-5:-1] \n",
        "#spliting the genres into a list\n",
        "movies['genres']=movies['genres'].str.split('|') \n",
        "#concatinate ratings with movies dataframe\n",
        "movies.dropna() \n",
        "movies.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juAmKVcsTemz"
      },
      "outputs": [],
      "source": [
        "#spliting the title cast into a list\n",
        "imdb = imdb_df.copy()\n",
        "imdb['title_cast']=imdb['title_cast'].str.split('|') \n",
        "imdb.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks52qc5gTem0"
      },
      "source": [
        "### Merging datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tif3Cg1sTem0"
      },
      "outputs": [],
      "source": [
        "train_eda = train_df.copy()\n",
        "con = pd.concat([train_df[:1000],movies], axis=1)\n",
        "con.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekRFaFuTTem1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df= pd.concat([imdb,con], axis=1)\n",
        "df.dropna(inplace=True)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHbdSyw7TqOq"
      },
      "outputs": [],
      "source": [
        "# Merging the tarin  and movies data\n",
        "data = pd.merge(train, movies, on='movieId')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgffvfy9TqOs"
      },
      "outputs": [],
      "source": [
        "#creating mean ratings data\n",
        "ratings = pd.DataFrame(data.groupby('title')['rating'].mean())\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvg8QsnyTqOu"
      },
      "outputs": [],
      "source": [
        "#creating number of ratings data\n",
        "ratings['number_of_ratings'] = data.groupby('title')['rating'].count()\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fAiES80Tem2"
      },
      "source": [
        "### Data Visualisation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "5bbFKbdaTqOx",
        "outputId": "4a0788d7-6ac9-4e68-cc4d-042e61560d19"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1456f281eb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m recmetrics.long_tail_plot(df=data, \n\u001b[0m\u001b[1;32m      3\u001b[0m              \u001b[0mitem_id_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0minteraction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"movie ratings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mpercentage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recmetrics' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "recmetrics.long_tail_plot(df=data, \n",
        "             item_id_column=\"movieId\", \n",
        "             interaction_type=\"movie ratings\", \n",
        "             percentage=0.5,\n",
        "             x_labels=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzhpGqeyTqOy"
      },
      "source": [
        "The plot plot shows the distribution of ratings/movie popularity with 653 polpular movies and 45760 unpopular movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZLepwqUTem2"
      },
      "source": [
        "**Movie Ratings from the User**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4p9EY72AaCRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oXBA9NZMTem2",
        "outputId": "623e95bf-9d41-4e6f-a49d-ec28afc4c841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c22ca4583067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Distplot of ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Distplot of ratings \n",
        "sns.distplot(df[\"rating\"], color='blue');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZDP98XTVTqO1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9rxVGhyTem2"
      },
      "source": [
        "**Exploring Movie Genres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VKpJP_oDTem2",
        "outputId": "408492f7-1d1c-4b2b-f9ed-22e349ca9215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8db1716b6fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ploting top genres in the Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Popular Genres'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Ploting top genres in the Dataset\n",
        "plt.figure(figsize=(20, 10))\n",
        "gen = df['genres'].explode()\n",
        "ax=sns.countplot(x=gen, order=gen.value_counts().index[:30],color='blue')\n",
        "ax.set_title('Popular Genres', fontsize=15)\n",
        "plt.xticks(rotation =90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6-i4HKuTqO4"
      },
      "source": [
        "Drama, Comedy and Thriller are top 3 most common movie genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqqvN8rsTem3"
      },
      "source": [
        "#### Movies made per year "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWMpxS9FTem3"
      },
      "outputs": [],
      "source": [
        "# Plot movies released per year\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.set(style=\"darkgrid\")\n",
        "ax = sns.countplot(y=movies['release_year'], data=df, order=df['release_year'].value_counts().index[0:30],color='blue')\n",
        "ax.set_title('Total Movies Released per Year', fontsize= 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LmJ4g8hTqPA"
      },
      "source": [
        "from 1955 The number of movies released each year increased, whereas it was previously fluctuating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRUYOLMYTem3"
      },
      "source": [
        "#### Popular Cast Members "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVJCR3i8Tem3"
      },
      "outputs": [],
      "source": [
        "# Plot popular cast\n",
        "plt.figure(figsize = (20,5))\n",
        "cast=imdb['title_cast'].explode()\n",
        "ax=sns.countplot(x=cast, order = cast.value_counts().index[:30],color='red')\n",
        "ax.set_title('Popular Cast',fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3SLn8iLTqPE"
      },
      "source": [
        "The most well-known cast members are Samuel L. Jackson and Steve Buscemi, with the remaining members having a slight variation in recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DxB6DSBTem3"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "cast = df['title_cast'].explode()\n",
        "text = list(set(cast))\n",
        "plt.rcParams['figure.figsize'] = (13, 13)\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100,background_color=\"white\").generate(str(text))\n",
        "\n",
        "plt.imshow(wordcloud,interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yzpS_WWTem4"
      },
      "source": [
        "### Movie Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8gu5S-RTem4"
      },
      "outputs": [],
      "source": [
        "# Describe the runtime \n",
        "df['runtime'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jDE9TnXTem4"
      },
      "outputs": [],
      "source": [
        "#Plot the Runtime\n",
        "sns.set(style=\"darkgrid\", )\n",
        "sns.kdeplot(data=df['runtime'], shade=True, color='red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBP7PkzqTem5"
      },
      "source": [
        "#### Long Movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8IWKOlcTem5"
      },
      "outputs": [],
      "source": [
        "#Show movies with long lengths \n",
        "df[df['runtime'] > 0][['runtime', 'title', 'release_year']].sort_values('runtime', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfM5qKDmTem5"
      },
      "source": [
        "#### Short Movies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAl1tKrPTem5"
      },
      "outputs": [],
      "source": [
        "# Show movies with short lengths\n",
        "df[df['runtime'] > 0][['runtime', 'title', 'release_year']].sort_values('runtime').head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zdoofoQTem5"
      },
      "source": [
        "### Tags "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N9yAupWTem6"
      },
      "outputs": [],
      "source": [
        "tags = tags_df['tag']\n",
        "tags.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "928ZCtPmTem6"
      },
      "outputs": [],
      "source": [
        "#Plot tags \n",
        "plt.figure(figsize=(15, 5))\n",
        "ax = sns.countplot(x=tags, order = tags.value_counts().index[:20],color = 'blue')\n",
        "ax.set_title('Top Tags', fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba2pKmsfTem9"
      },
      "source": [
        "<a id=\"features\"></a>\n",
        "## 5. **Feature engineering And Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyqjnKGfTqPT"
      },
      "source": [
        "In this section, we extract features from raw data. The motivation is to use these extra features to improve the quality of results from a machine learning process, compared with supplying only the raw data to the machine learning process.\n",
        "\n",
        "The features engineered for content-based and collaborative filtering are different because methods do not use the same dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zULU_9xnTem9"
      },
      "source": [
        "### **Content-based Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xJa86KtTem9"
      },
      "source": [
        "#### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzTiIIzWTem9",
        "outputId": "b5f0dd91-ff0f-4086-d774-2cb91380068e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b5d8534-037b-4b1a-8ba4-33b99cfd1ea0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres</th>\n",
              "      <th>title_cast</th>\n",
              "      <th>director</th>\n",
              "      <th>plot_keywords</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Toy Story (1995)</th>\n",
              "      <td>[adventure, animation, children, comedy, fantasy]</td>\n",
              "      <td>[tomhanks, timallen, donrickles, jimvarney, wa...</td>\n",
              "      <td>johnlasseter</td>\n",
              "      <td>[toy, rivalry, cowboy, cgi animation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jumanji (1995)</th>\n",
              "      <td>[adventure, children, fantasy]</td>\n",
              "      <td>[robinwilliams, jonathanhyde, kirstendunst, br...</td>\n",
              "      <td>jonathanhensleigh</td>\n",
              "      <td>[board game, adventurer, fight, game]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grumpier Old Men (1995)</th>\n",
              "      <td>[comedy, romance]</td>\n",
              "      <td>[waltermatthau, jacklemmon, sophialoren, ann-m...</td>\n",
              "      <td>markstevenjohnson</td>\n",
              "      <td>[boat, lake, neighbor, rivalry]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Waiting to Exhale (1995)</th>\n",
              "      <td>[comedy, drama, romance]</td>\n",
              "      <td>[whitneyhouston, angelabassett, lorettadevine,...</td>\n",
              "      <td>terrymcmillan</td>\n",
              "      <td>[black american, husband wife relationship, be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Father of the Bride Part II (1995)</th>\n",
              "      <td>[comedy]</td>\n",
              "      <td>[stevemartin, dianekeaton, martinshort, kimber...</td>\n",
              "      <td>alberthackett</td>\n",
              "      <td>[fatherhood, doberman, dog, mansion]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b5d8534-037b-4b1a-8ba4-33b99cfd1ea0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b5d8534-037b-4b1a-8ba4-33b99cfd1ea0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b5d8534-037b-4b1a-8ba4-33b99cfd1ea0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                               genres  \\\n",
              "title                                                                                   \n",
              "Toy Story (1995)                    [adventure, animation, children, comedy, fantasy]   \n",
              "Jumanji (1995)                                         [adventure, children, fantasy]   \n",
              "Grumpier Old Men (1995)                                             [comedy, romance]   \n",
              "Waiting to Exhale (1995)                                     [comedy, drama, romance]   \n",
              "Father of the Bride Part II (1995)                                           [comedy]   \n",
              "\n",
              "                                                                           title_cast  \\\n",
              "title                                                                                   \n",
              "Toy Story (1995)                    [tomhanks, timallen, donrickles, jimvarney, wa...   \n",
              "Jumanji (1995)                      [robinwilliams, jonathanhyde, kirstendunst, br...   \n",
              "Grumpier Old Men (1995)             [waltermatthau, jacklemmon, sophialoren, ann-m...   \n",
              "Waiting to Exhale (1995)            [whitneyhouston, angelabassett, lorettadevine,...   \n",
              "Father of the Bride Part II (1995)  [stevemartin, dianekeaton, martinshort, kimber...   \n",
              "\n",
              "                                             director  \\\n",
              "title                                                   \n",
              "Toy Story (1995)                         johnlasseter   \n",
              "Jumanji (1995)                      jonathanhensleigh   \n",
              "Grumpier Old Men (1995)             markstevenjohnson   \n",
              "Waiting to Exhale (1995)                terrymcmillan   \n",
              "Father of the Bride Part II (1995)      alberthackett   \n",
              "\n",
              "                                                                        plot_keywords  \n",
              "title                                                                                  \n",
              "Toy Story (1995)                                [toy, rivalry, cowboy, cgi animation]  \n",
              "Jumanji (1995)                                  [board game, adventurer, fight, game]  \n",
              "Grumpier Old Men (1995)                               [boat, lake, neighbor, rivalry]  \n",
              "Waiting to Exhale (1995)            [black american, husband wife relationship, be...  \n",
              "Father of the Bride Part II (1995)               [fatherhood, doberman, dog, mansion]  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols = ['title','genres','title_cast','director','plot_keywords']\n",
        "\n",
        "#create new dataframe with useful data\n",
        "data_df = train_df[cols]\n",
        "\n",
        "#set index to movie titles\n",
        "data_df.set_index('title', inplace = True)\n",
        "\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO-yLTxETem9"
      },
      "source": [
        "Now we create the bag of words from the genres, title_cast,director and plot keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg-3kSNQTem-"
      },
      "outputs": [],
      "source": [
        "data_df['bag_of_words'] = ''\n",
        "columns = data_df.columns\n",
        "for index, row in data_df.iterrows():\n",
        "    words = ''\n",
        "    for col in columns:\n",
        "        if col != 'director':\n",
        "            words = words + ' '.join(row[col])+ ' '\n",
        "        else:\n",
        "            words = words + row[col]+ ' '\n",
        "    row['bag_of_words'] = words\n",
        "    \n",
        "data_df.drop(columns = [col for col in data_df.columns if col!= 'bag_of_words'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRbPtSHATem-"
      },
      "source": [
        "**Vectorization**\n",
        "\n",
        "The data we have is text, but machine learning algorithms operate on a numeric feature space, expecting input as a two-dimensional array where rows are instances and columns are features. In order to perform machine learning on text, we need to transform our documents into vector representations such that we can apply numeric machine learning. We make use of two vectorization techniques:\n",
        "\n",
        "- CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. The value of each cell is nothing but the count of the word in that particular text sample.\n",
        "\n",
        "From the  bag of words, we generate numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEBLrw-BTem-",
        "outputId": "75255331-9443-4c10-9e5b-4e2b91e9614a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                      Toy Story (1995)\n",
              "1                        Jumanji (1995)\n",
              "2               Grumpier Old Men (1995)\n",
              "3              Waiting to Exhale (1995)\n",
              "4    Father of the Bride Part II (1995)\n",
              "5                           Heat (1995)\n",
              "6                        Sabrina (1995)\n",
              "7                   Tom and Huck (1995)\n",
              "8                   Sudden Death (1995)\n",
              "9                      GoldenEye (1995)\n",
              "Name: title, dtype: object"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# instantiating and generating the count matrix\n",
        "count = CountVectorizer()\n",
        "count_matrix = count.fit_transform(data_df['bag_of_words'])\n",
        "new_matrix = count_matrix\n",
        "# creating a Series for the movie titles.\n",
        "indices = pd.Series(data_df.index)\n",
        "indices[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdcr2mQvTqPg"
      },
      "source": [
        "**Feature scaling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8zh1QC0TqPh"
      },
      "source": [
        "It is possible for features to have different scales, there is a chance that higher weightage is given to features with higher magnitude. This will impact the performance of the machine learning algorithm and obviously, we do not want our algorithm to be biassed towards certain features. \n",
        "\n",
        "MaxAbsScaler estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEnYIWHaTqPi"
      },
      "outputs": [],
      "source": [
        "# initialise a scaler\n",
        "\n",
        "scaler = MaxAbsScaler() \n",
        "\n",
        "scaled_new_matrix = scaler.fit_transform(new_matrix) # scaled new_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT_l8_9xTem-"
      },
      "source": [
        "### **Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHjTixk8Tem-"
      },
      "source": [
        "<a id=\"model\"></a>\n",
        "## 6. **Model Building And Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV_RoCpuTqPl"
      },
      "source": [
        "The method of learning is unsupervised, hence this type of algorithm learns patterns from untagged data. The hope is that through mimicry, which is an important mode of learning in people, the machine is forced to build a compact internal representation of its world and then generate imaginative content from it. \n",
        "\n",
        "We use two forms of recommender system algorithms: content-based and collaborative filtering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD52dq-dTem-"
      },
      "source": [
        "### **Content-based Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS_-iqlPTqPn"
      },
      "source": [
        "From the features engineered, we find the similarities within the data. This is done by computing the cosine similarity.\n",
        "\n",
        "Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olb7R1T3TqPo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVz6xI9mTem_"
      },
      "outputs": [],
      "source": [
        "# generating the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1827I9zTqPq"
      },
      "source": [
        "With our content similarity matrix computed,     \n",
        "\n",
        "We now do recommendations by: \n",
        "\n",
        "  1. Select an initial item (movie) to generate recommendations from. \n",
        "  2. Extract all the similarity values between the initial item and each other item in the similarity matrix.\n",
        "  3. Sort the resulting values in descending order. \n",
        "  4. Select the top N similarity values, and return the corresponding item details to the user. This is now our simple top-N list.  \n",
        "  \n",
        "We implement this algorithmic process in the function below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVtFiQIFTem_"
      },
      "outputs": [],
      "source": [
        "def recommendations(title, cosine_sim = cosine_sim):\n",
        "    \n",
        "    recommended_movies = []\n",
        "    \n",
        "    # gettin the index of the movie that matches the title\n",
        "    idx = indices[indices == title].index[0]\n",
        "\n",
        "    # creating a Series with the similarity scores in descending order\n",
        "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "\n",
        "    # getting the indexes of the 10 most similar movies\n",
        "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
        "    \n",
        "    # populating the list with the titles of the best 10 matching movies\n",
        "    for i in top_10_indexes:\n",
        "        recommended_movies.append(list(data_df.index)[i])\n",
        "        \n",
        "    return recommended_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17VRsnsMTem_"
      },
      "outputs": [],
      "source": [
        "# recommendations for the movie\n",
        "recommendations('Hard Target (1993)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51-ebsQVh3-l"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGgMcKWta7ow"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7sAHH0ZbmWP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnx3iB4KZKlJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v2iMjvOZYJp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBFbEW9eZ5NL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBGYmYf0Tem_"
      },
      "source": [
        "### **Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users.\n",
        "\n",
        "Because it’s based on historical data, the core assumption here is that the users who have agreed in the past tend to also agree in the future. In terms of user preference, it usually expressed by two categories, Explicit and Implicit rating. \n",
        "\n",
        "**Explicit Rating**, is a rate given by a user to an item on a sliding scale, \n",
        "like 5 stars for Titanic. This is the most direct feedback from users to show how much they like an item.\n",
        "\n",
        "**Implicit Rating**, suggests users preference indirectly, such as page views, clicks, purchase records, whether or not listen to a music track, and so on."
      ],
      "metadata": {
        "id": "8ITM0gB6Yn8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this predict explicit data rating will be used. **Surprise** is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
        "\n",
        "**Surprise:**\n",
        "\n",
        "Provides various ready-to-use prediction algorithms such as baseline algorithms, neighborhood methods, matrix factorization-based ( SVD, PMF, SVDpp, NMF), and many others.\n",
        "Provides tools to evaluate, analyse and compare the algorithms’ performance.\n",
        "From the Suprise library, the follwoing algorithms were used:"
      ],
      "metadata": {
        "id": "lhiGtqmjT9NP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic algorithms\n",
        "\n",
        "\n",
        "**NormalPredictor:** this algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal.\n",
        "\n",
        "**BaselineOnly:** this algorithm predicts the baseline estimate for given user and item.\n",
        "\n",
        "**k-NN algorithms**\n",
        "\n",
        "**KNNBasic:** this is a basic collaborative filtering algorithm.\n",
        "\n",
        "**KNNWithMeans:** this is a basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
        "\n",
        "**KNNWithZScore:** this is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
        "\n",
        "**KNNBaseline:** is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
        "\n",
        "**Matrix Factorization-based algorithms**\n",
        "\n",
        "**SVD:** this algorithm is equivalent to Probabilistic Matrix Factorization ( which makes use of data provided by users with similar preferences to offer recommendations to a particular user).\n",
        "\n",
        "**SVDpp:** this algorithm is an extension of SVD that takes into account implicit ratings.\n",
        "\n",
        "**NMF:** this is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD.\n",
        "\n",
        "**SlopeOne:** this is a straightforward implementation of the SlopeOne algorithm.\n",
        "\n",
        "**Coclustering:** is a collaborative filtering algorithm based on co-clustering."
      ],
      "metadata": {
        "id": "RyQGOkZKUCfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading 10000 dataset\n",
        "data = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']].head(10000), Reader)"
      ],
      "metadata": {
        "id": "E_8BrpvOT1Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement an algorithm\n",
        "algo = [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), \n",
        "                  KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]\n",
        "\n",
        "#Read 10000 dataset\n",
        "data2 = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']].head(10000), Reader())\n",
        "\n",
        "#Implementing algorithm for RMSE\n",
        "algo_rmse=[]\n",
        "for a in algo:\n",
        "    \n",
        "    cross_valid=cross_validate(a, data2, measures=['RMSE'], cv = 3)\n",
        "    output=pd.DataFrame.from_dict(cross_valid).mean(axis=0)\n",
        "    output=output.append(pd.Series([str(a).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
        "    algo_rmse.append(output)\n",
        "\n",
        "algo_rmse\n",
        "surprise_results = pd.DataFrame(algo_rmse).set_index('Algorithm').sort_values('test_rmse')\n",
        "surprise_results"
      ],
      "metadata": {
        "id": "SOYg2nkQUxkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the table above containing test_rmse, fit_time, test_time values for the algorithms, we notice that the SVDpp, SVD and BaselineOnly algorithms are top three best performing algorithms. Therefore the best performing algorithm will be used for prediction and to find the Root Mean Squared Error (RMSE) values."
      ],
      "metadata": {
        "id": "T7ftxpyLXihS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting with SVDpp Algorithm**"
      ],
      "metadata": {
        "id": "bt8DpYh4VFNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading 100000 dataset\n",
        "data3 = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']].head(100000), Reader()) "
      ],
      "metadata": {
        "id": "smW1-04dU1Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data3, test_size=0.05)"
      ],
      "metadata": {
        "id": "Kn4Evkx8U7Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "#SVDpp model\n",
        "svdpp=SVDpp(n_epochs = 30, n_factors = 200, init_std_dev = 0.05, random_state=42)\n",
        "\n",
        "#Fitting the model\n",
        "svdpp.fit(trainset)\n",
        "\n",
        "# Making prediction on the validation dataset\n",
        "test_pred= svdpp.test(testset)\n",
        "\n",
        "#Evaluating model performance\n",
        "rsme_collabo = accuracy.rmse(test_pred,\n",
        "                             verbose=True)"
      ],
      "metadata": {
        "id": "g9kUKwt1Vs1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the rating for each user and movie\n",
        "ratings=[]\n",
        "for x,y in test_df.itertuples(index=False):\n",
        "    output=svdpp.predict(x,y)\n",
        "    ratings.append(output)\n",
        "    \n",
        "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
        "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
        "output_df=output_df[['ID','est']]\n",
        "output_df.head()"
      ],
      "metadata": {
        "id": "km_AWG2oVyw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting with SVD Algorithm**"
      ],
      "metadata": {
        "id": "IeGvMDDPVU-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading 1000000 dataset\n",
        "data4 = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']].head(1000000), Reader()) "
      ],
      "metadata": {
        "id": "QUWZmugbVfSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data4, test_size=0.05)"
      ],
      "metadata": {
        "id": "p-fMDLzpVltg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "#SVD model\n",
        "svd=SVD(n_epochs = 30, n_factors = 200, init_std_dev = 0.05, random_state=42)\n",
        "\n",
        "#Fitting the model\n",
        "svd.fit(trainset)\n",
        "\n",
        "# Making prediction on the validation dataset\n",
        "test_pred= svd.test(testset)\n",
        "\n",
        "#Evaluating model performance\n",
        "rsme_collabo = accuracy.rmse(test_pred,\n",
        "                             verbose=True)"
      ],
      "metadata": {
        "id": "sC-fQ-4eVoS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the rating for each user and movie\n",
        "ratings=[]\n",
        "for x,y in test_df.itertuples(index=False):\n",
        "    output=svd.predict(x,y)\n",
        "    ratings.append(output)\n",
        "    \n",
        "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
        "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
        "output_df=output_df[['ID','est']]\n",
        "output_df.head()"
      ],
      "metadata": {
        "id": "i-ngr9WcVqoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting with BaselineOnly algorithm**"
      ],
      "metadata": {
        "id": "WN03dNYSWAe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading 1000000 dataset\n",
        "data5 = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']].head(1000000), Reader()) "
      ],
      "metadata": {
        "id": "MR3jKMBAWHZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data5, test_size=0.05)"
      ],
      "metadata": {
        "id": "t-mXO2xvWU0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "#BaselineOnly model\n",
        "bsl_options = {'method': 'sgd','n_epochs': 40}\n",
        "blo=BaselineOnly(bsl_options=bsl_options)\n",
        "\n",
        "#Fitting the model\n",
        "blo.fit(trainset)\n",
        "\n",
        "# Making prediction on the validation dataset\n",
        "test_pred= blo.test(testset)\n",
        "\n",
        "#Evaluating model performance\n",
        "rsme_collabo = accuracy.rmse(test_pred,\n",
        "                             verbose=True)"
      ],
      "metadata": {
        "id": "bxwAKppuWZk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the rating for each user and movie\n",
        "ratings=[]\n",
        "for x,y in test_df.itertuples(index=False):\n",
        "    output=blo.predict(x,y)\n",
        "    ratings.append(output)\n",
        "    \n",
        "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
        "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
        "output_df=output_df[['ID','est']]\n",
        "output_df.head()"
      ],
      "metadata": {
        "id": "fnV8KO56WedL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBQTAqA5Tem_"
      },
      "source": [
        "<a id=\"evaluation\"></a>\n",
        "## 7. **Model Parameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-12T15:45:15.534915Z",
          "iopub.status.busy": "2022-01-12T15:45:15.534602Z",
          "iopub.status.idle": "2022-01-12T15:45:15.538707Z",
          "shell.execute_reply": "2022-01-12T15:45:15.537874Z",
          "shell.execute_reply.started": "2022-01-12T15:45:15.534881Z"
        },
        "id": "NKJOoagDTem_"
      },
      "outputs": [],
      "source": [
        "\n",
        "params = {'n_epochs' : 12,\n",
        "           'init_std_dev': 0.01,\n",
        "           'n_factors' : 160,\n",
        "          'model_name' : 'SVDpp'}\n",
        "\n",
        "RMSE = 0.84443\n",
        "metrics = RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-12T15:45:15.540766Z",
          "iopub.status.busy": "2022-01-12T15:45:15.540023Z",
          "iopub.status.idle": "2022-01-12T15:45:15.552333Z",
          "shell.execute_reply": "2022-01-12T15:45:15.551491Z",
          "shell.execute_reply.started": "2022-01-12T15:45:15.540720Z"
        },
        "id": "jxIZRkZoTem_"
      },
      "outputs": [],
      "source": [
        "# log our parameters and results\n",
        "\n",
        "experiment.log_parameters(params)\n",
        "\n",
        "experiment.log_parameters(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-12T15:45:15.554015Z",
          "iopub.status.busy": "2022-01-12T15:45:15.553561Z",
          "iopub.status.idle": "2022-01-12T15:45:15.570316Z",
          "shell.execute_reply": "2022-01-12T15:45:15.569325Z",
          "shell.execute_reply.started": "2022-01-12T15:45:15.553977Z"
        },
        "id": "-uZrLBmZTenA",
        "outputId": "41c51c40-2f41-4377-8d28-cf73b279bf9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/kwanda2426/streamlit-based-movie-recommender-system/d69f8ff97ef5447fa556f633a134fb40\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     imag         : 0.0\n",
            "COMET INFO:     init_std_dev : 0.01\n",
            "COMET INFO:     model_name   : SVDpp\n",
            "COMET INFO:     n_epochs     : 12\n",
            "COMET INFO:     n_factors    : 160\n",
            "COMET INFO:     real         : 0.84443\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     environment details      : 1\n",
            "COMET INFO:     filename                 : 1\n",
            "COMET INFO:     git metadata             : 1\n",
            "COMET INFO:     git-patch (uncompressed) : 1 (10.63 MB)\n",
            "COMET INFO:     installed packages       : 1\n",
            "COMET INFO:     notebook                 : 1\n",
            "COMET INFO:     source_code              : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Uploading 1 metrics, params and output messages\n",
            "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
            "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
            "COMET INFO: Still uploading 2 file(s), remaining 3.73 KB/3.30 MB\n"
          ]
        }
      ],
      "source": [
        "# ending the experiment\n",
        "\n",
        "experiment.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6VOLCoTenA"
      },
      "source": [
        "<a id=\"conclusion\"></a>\n",
        "## 8. **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFeFNGOVTenA"
      },
      "source": [
        "<a id=\"references\"></a>\n",
        "## 9. **References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73iTrpyVTqP9"
      },
      "source": [
        "1. Hakami, A., 2022. Movie Recommendation system. [online] Medium. Available at: <https://medium.com/mlearning-ai/movie-recommendation-system-f2f57290b1b8> [Accessed 24 January 2022]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwNi61jXTqP-"
      },
      "source": [
        "2. abramovsky, O., 2022. How to generate recommendations using TF-IDF. [online] Medium. Available at: <https://medium.com/codex/how-to-generate-recommendations-using-tf-idf-52d46eca606f> [Accessed 27 January 2022]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQiiLDygTqQF"
      },
      "source": [
        "3. Youtube.com. 2022. Overview of recommender systems. [online] Available at: <https://www.youtube.com/watch?v=1JRrCEgiyHM> [Accessed 16 January 2022]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKMIrDFgTqQG"
      },
      "source": [
        "4. Youtube.com. 2022. Content-based Filtering. [online] Available at: <https://www.youtube.com/watch?v=2uxXPzm-7FY> [Accessed 16 January 2022]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYpSny3LTqQP"
      },
      "source": [
        "5. Youtube.com. 2022. Collaborating Filtering. [online] Available at: <https://www.youtube.com/watch?v=h9gpufJFF-0> [Accessed 16 January 2022]."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Team_14 notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}