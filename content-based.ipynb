{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import our regular old heroes \nimport numpy as np\nimport pandas as pd\nimport scipy as sp # <-- The sister of Numpy, used in our code for numerical efficientcy. \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nfrom sklearn.metrics import mean_squared_error\n\n\n# Entity featurization and similarity computation\nfrom sklearn.metrics.pairwise import cosine_similarity \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Libraries used during sorting procedures.\nimport operator # <-- Convienient item retrieval during iteration \nimport heapq # <-- Efficient sorting of large lists\n\n# Imported for our sanity\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T08:01:53.794045Z","iopub.execute_input":"2022-02-01T08:01:53.794632Z","iopub.status.idle":"2022-02-01T08:01:54.764115Z","shell.execute_reply.started":"2022-02-01T08:01:53.794475Z","shell.execute_reply":"2022-02-01T08:01:54.763033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making sure that we can see all rows and cols\npd.set_option('display.max_columns', None)\n\npd.set_option('display.max_rows', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imdb\n#imdb_data = pd.read_csv(\"../input/edsa-movie-recommendation-wilderness/imdb_data.csv\")\n\n#test\n#test = pd.read_csv(\"../input/edsa-movie-recommendation-wilderness/test.csv\")\n\n#movies\nmovies = pd.read_csv(\"../input/edsa-movie-recommendation-wilderness/movies.csv\")\n\n#train\ncols_list = ['userId', 'movieId', 'rating']\ntrain = pd.read_csv(\"../input/edsa-movie-recommendation-wilderness/train.csv\", usecols = cols_list)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:02:12.138542Z","iopub.execute_input":"2022-02-01T08:02:12.139614Z","iopub.status.idle":"2022-02-01T08:02:17.485565Z","shell.execute_reply.started":"2022-02-01T08:02:12.139542Z","shell.execute_reply":"2022-02-01T08:02:17.484338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#############works, don't touch##################","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merging dataframe\n\ntrain_df = movies","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:02:24.117006Z","iopub.execute_input":"2022-02-01T08:02:24.117314Z","iopub.status.idle":"2022-02-01T08:02:24.122376Z","shell.execute_reply.started":"2022-02-01T08:02:24.117281Z","shell.execute_reply":"2022-02-01T08:02:24.121213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[:27000]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:02:31.238773Z","iopub.execute_input":"2022-02-01T08:02:31.239132Z","iopub.status.idle":"2022-02-01T08:02:31.244326Z","shell.execute_reply.started":"2022-02-01T08:02:31.2391Z","shell.execute_reply":"2022-02-01T08:02:31.243333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:02:53.191407Z","iopub.execute_input":"2022-02-01T08:02:53.191683Z","iopub.status.idle":"2022-02-01T08:02:53.198046Z","shell.execute_reply.started":"2022-02-01T08:02:53.191654Z","shell.execute_reply":"2022-02-01T08:02:53.19729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert data types to strings for string handling\n#train_df['genres'] = train_df.genres.astype(str)\n#train_df['title_cast'] = train_df.title_cast.astype(str)\n#train_df['director'] = train_df.director.astype(str)\n#train_df['plot_keywords'] = train_df.plot_keywords.astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Every genre is separated by a | \ntrain_df['genres'] = train_df['genres'].map(lambda x: x.lower().split('|'))\n\n# Every title cast is separated by a | so we simply have to call the split function on | and separate them by ,\n#train_df['title_cast'] = train_df['title_cast'].str.split('|')\n\n# And we will do the same thing for the plot keywords\n#train_df['plot_keywords'] = train_df['plot_keywords'].str.split('|')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:03:05.303998Z","iopub.execute_input":"2022-02-01T08:03:05.304482Z","iopub.status.idle":"2022-02-01T08:03:05.330774Z","shell.execute_reply.started":"2022-02-01T08:03:05.304424Z","shell.execute_reply":"2022-02-01T08:03:05.329682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def string_function(x):\n#    \"\"\"merges name and surname into one name\"\"\"\n#    if isinstance(x, list):\n#        return [str.lower(i.replace(\" \", \"\")) for i in x]\n#    else:\n#        #Check if director exists. If not, return empty string\n#        if isinstance(x, str):\n#            return str.lower(x.replace(\" \", \"\"))\n#        else:\n#            return ''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features = ['title_cast','director']\n\n#for feature in features:\n#    train_df[feature] = train_df[feature].apply(string_function)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['title','genres']","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:03:13.650224Z","iopub.execute_input":"2022-02-01T08:03:13.650505Z","iopub.status.idle":"2022-02-01T08:03:13.654927Z","shell.execute_reply.started":"2022-02-01T08:03:13.650475Z","shell.execute_reply":"2022-02-01T08:03:13.654269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = train_df[cols]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:03:16.379189Z","iopub.execute_input":"2022-02-01T08:03:16.379491Z","iopub.status.idle":"2022-02-01T08:03:16.386379Z","shell.execute_reply.started":"2022-02-01T08:03:16.379458Z","shell.execute_reply":"2022-02-01T08:03:16.385676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generating the cosine similarity matrix\n#cosine_ = cosine_similarity(count_matrix, count_matrix)\n\n#import pickle\n\n#model_save_path = \"./cosine_sim_.pkl\"\n#with open(model_save_path,'wb') as file:\n#    pickle.dump(cosine_sim,file, protocol = 4)\n#pickle.dump(d, open(\"file\", 'w'), protocol=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.set_index('title', inplace = True)\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:03:22.78942Z","iopub.execute_input":"2022-02-01T08:03:22.789706Z","iopub.status.idle":"2022-02-01T08:03:22.801381Z","shell.execute_reply.started":"2022-02-01T08:03:22.789678Z","shell.execute_reply":"2022-02-01T08:03:22.800685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['bag_of_words'] = ''\ncolumns = data_df.columns\nfor index, row in data_df.iterrows():\n    words = ''\n    for col in columns:\n        if col != 'director':\n            words = words + ' '.join(row[col])+ ' '\n        else:\n            words = words + row[col]+ ' '\n    row['bag_of_words'] = words\n    \ndata_df.drop(columns = [col for col in data_df.columns if col!= 'bag_of_words'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:03:48.763849Z","iopub.execute_input":"2022-02-01T08:03:48.764565Z","iopub.status.idle":"2022-02-01T08:03:50.478882Z","shell.execute_reply.started":"2022-02-01T08:03:48.764506Z","shell.execute_reply":"2022-02-01T08:03:50.477819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:07:16.07845Z","iopub.execute_input":"2022-02-01T08:07:16.078759Z","iopub.status.idle":"2022-02-01T08:07:16.089008Z","shell.execute_reply.started":"2022-02-01T08:07:16.078729Z","shell.execute_reply":"2022-02-01T08:07:16.088403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiating and generating the count matrix\ncount = CountVectorizer()\ncount_matrix = count.fit_transform(data_df['bag_of_words'])\n\n# creating a Series for the movie titles so they are associated to an ordered numerical\n# list I will use later to match the indexes\nindices = pd.Series(data_df.index)\nindices[:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:03:57.660776Z","iopub.execute_input":"2022-02-01T08:03:57.661079Z","iopub.status.idle":"2022-02-01T08:03:57.780955Z","shell.execute_reply.started":"2022-02-01T08:03:57.661043Z","shell.execute_reply":"2022-02-01T08:03:57.779835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generating the cosine similarity matrix\ncosine_sim = cosine_similarity(count_matrix, count_matrix)\n\nimport pickle\n\nmodel_save_path = \"./cosine_sim.pkl\"\nwith open(model_save_path,'wb') as file:\n    pickle.dump(cosine_sim,file, protocol = 4)\n#pickle.dump(d, open(\"file\", 'w'), protocol=4)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T08:04:05.170317Z","iopub.execute_input":"2022-02-01T08:04:05.171001Z","iopub.status.idle":"2022-02-01T08:05:22.557516Z","shell.execute_reply.started":"2022-02-01T08:04:05.170943Z","shell.execute_reply":"2022-02-01T08:05:22.556169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommendations(title, cosine_sim = cosine_sim):\n    \n    recommended_movies = []\n    \n    # gettin the index of the movie that matches the title\n    idx = indices[indices == title].index[0]\n\n    # creating a Series with the similarity scores in descending order\n    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n\n    # getting the indexes of the 10 most similar movies\n    top_10_indexes = list(score_series.iloc[1:11].index)\n    \n    # populating the list with the titles of the best 10 matching movies\n    for i in top_10_indexes:\n        recommended_movies.append(list(data_df.index)[i])\n        \n    return recommended_movies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommendations('Hard Target (1993)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##################works, don't touch#######################################","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}